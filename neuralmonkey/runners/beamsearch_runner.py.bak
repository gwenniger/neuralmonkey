from typing import Callable, List, Dict, Optional

import numpy as np
from typeguard import check_argument_types

from neuralmonkey.model.model_part import ModelPart
from neuralmonkey.decoders.beam_search_decoder import (BeamSearchDecoder,
                                                       SearchStepOutput)
from neuralmonkey.runners.base_runner import (BaseRunner, Executable,
                                              ExecutionResult, NextExecute)
from neuralmonkey.vocabulary import Vocabulary, END_TOKEN

BeamSearchLoopState = NamedTuple("BeamSearchLoopState",
                                 [("bs_state", SearchState),
                                  ("bs_output", SearchStepOutputTA),
                                  ("decoder_loop_state", LoopState)])

class BeamSearchExecutable(Executable):
    def __init__(self,
                 rank: int,
                 all_encoders: List[ModelPart],
                 bs_outputs: SearchStepOutput,
                 vocabulary: Vocabulary,
                 max_steps: int,
                 postprocess: Optional[Callable]) -> None:

        self._rank = rank
        self._all_encoders = all_encoders
        self._bs_outputs = bs_outputs
        self._vocabulary = vocabulary
        self._max_steps = max_steps
        self._postprocess = postprocess

        self.result = None  # type: Optional[ExecutionResult]

    def next_to_execute(self) -> NextExecute:
        return self._all_encoders, {'bs_outputs': self._bs_outputs}, {} #{self._decoder.get_initial_loop_state : self._ensemble_loop_state}

    def collect_results(self, results: List[Dict]) -> None:
        #if len(results) > 1:
        #    raise ValueError("Beam search runner does not support ensembling.")

        #evaluated_bs = results[0]['bs_outputs']

        return

        ens_output = []
        ens_state = []
        ens_decoder_loop_state = []

        # beam_size x vocabulary_size
        # Contains info about averaged score and pointer
        # to corresponding session-beams
        ens_scores = {}
        for sess_idx in len(results):
            bs_output = results[sess_idx]['bs_output']

            for hyp_idx in len(bs_output.scores[-1]):
                parent_id = bs_output.parent_ids[-1][hyp_idx]
                token_id = bs_output.token_ids[-1][hyp_idx]
                ens_id = parent_id * len(self._vocabulary) + token_id
                if ens_scores[ens_id] is None:
                    ens_scores[ens_id] = (0, [])
                ens_scores[ens_id][0] += bs_output.scores[-1][hyp_idx] / len(results)
                ens_scores[ens_id][1].append(sess_idx * len(results) + hyp_idx)

        # Collect ensembled beam scores and indices
        top_k_scores = sorted(d.iteritems(), key=lambda x: -x[1][0])[:self._decoder.beam_size]
        
        # Check if the hypothesis self._rank isn't finished
        finished = 1
        for candidate_idx in tok_k_scores[self._rank - 1][1]:
            sess_idx = candidate_idx // len(results)
            hyp_idx = candidate_idx % len(results)
            finished *= results[sess_idx]['bs_state'].finished[hyp_idx]

        if finished:
            # All the path that share the score should be identical
            self.prepare_result(results, tok_k_scores[self._rank - 1])
            return

        # Otherwise prepare new bs_loop_state
        for sess_idx in len_results:
            results[sess_idx]['bs_output'].scores[-1

    def prepare_result(self, results, rank_k_entry):
        output_tokens = []  # type: List[str]
        rank_k_idx = rank_k_entry[1][0]
        bs_score = rank_k_entry[0]

        sess_idx = rank_k_idx // len(results)
        hyp_idx = rank_k_idx % len(results)
        for time in reversed(range(self._max_steps)):
            bs_output = results[sess_idx]['bs_output']
            token_id = bs_output.token_ids[time][hyp_idx]
            token = self._vocabulary.index_to_word[token_id]
            output_tokens.append(token)
            hyp_idx = bs_output.parent_ids[time][hyp_idx]

        output_tokens.reverse()

        before_eos_tokens = []  # type: List[str]
        for tok in output_tokens:
            if tok == END_TOKEN:
                break
            before_eos_tokens.append(tok)

        if self._postprocess is not None:
            decoded_tokens = self._postprocess([before_eos_tokens])
        else:
            decoded_tokens = [before_eos_tokens]

        self.result = ExecutionResult(
            outputs=decoded_tokens,
            losses=[bs_score],
            scalar_summaries=None,
            histogram_summaries=None,
            image_summaries=None)


class BeamSearchRunner(BaseRunner):
    def __init__(self,
                 output_series: str,
                 decoder: BeamSearchDecoder,
                 rank: int = 1,
                 postprocess: Callable[[List[str]], List[str]] = None) -> None:
        super(BeamSearchRunner, self).__init__(output_series, decoder)
        check_argument_types()

        if rank < 1 or rank > decoder.beam_size:
            raise ValueError(
                ("Rank of output hypothesis must be between 1 and the beam "
                 "size ({}), was {}.").format(decoder.beam_size, rank))

        self._rank = rank
        self._postprocess = postprocess

    def get_executable(self,
                       compute_losses: bool = False,
                       summaries: bool = True) -> BeamSearchExecutable:
        return BeamSearchExecutable(
            self._rank, self.all_coders, self._decoder.outputs,
            self._decoder.vocabulary, self._decoder.max_steps,
            self._postprocess)

    @property
    def loss_names(self) -> List[str]:
        return ["beam_search_score"]

    @property
    def decoder_data_id(self) -> Optional[str]:
        return None


def beam_search_runner_range(output_series: str,
                             decoder: BeamSearchDecoder,
                             max_rank: int = None,
                             postprocess: Callable[
                                 [List[str]], List[str]]=None
                            ) -> List[BeamSearchRunner]:
    """A list of beam search runners for a range of ranks from 1 to max_rank.

    This means there is max_rank output series where the n-th series contains
    the n-th best hypothesis from the beam search.

    Args:
        output_series: Prefix of output series.
        decoder: Beam search decoder shared by all runners.
        max_rank: Maximum rank of the hypotheses.
        postprocess: Series-level postprocess applied on output.

    Returns:
        List of beam search runners getting hypotheses with rank from 1 to
        max_rank.
    """
    check_argument_types()

    if max_rank is None:
        max_rank = decoder.beam_size

    if max_rank > decoder.beam_size:
        raise ValueError(
            ("The maximum rank ({}) cannot be "
             "bigger than beam size {}.").format(
                 max_rank, decoder.beam_size))

    return [BeamSearchRunner("{}.rank{:03d}".format(output_series, r),
                             decoder, r, postprocess)
            for r in range(1, max_rank + 1)]
